{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.tagger import generateTags\n",
    "from Scripts.evaluator import eval\n",
    "from Scripts.plotting import plot_result\n",
    "from Scripts.toolOverlap import getOverlap\n",
    "from Scripts.election import electLabel\n",
    "from Scripts.toolOverlap_perVuln import getOverlapPerV\n",
    "from Scripts.ToolEfficiency import get_toolEfficiency\n",
    "from Scripts.createPerformanceOutFiles import createPerformanceOutFiles\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Stop warnings\n",
    "import warnings as w\n",
    "w.simplefilter(action='ignore',category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tools = ['MAIAN','Mythril','Semgrep','Slither','Solhint','VeriSmart']\n",
    "Bases = ['TestSet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create avgAnalysisTimeAndFailureRate files if not exit\n",
    "files = os.listdir('./Results/Performance/')\n",
    "if not 'avgAnalysisTimeAndFailureRate.csv' in files or not 'avgAnalysisTimeAndFailureRate_Fair.csv' in files:\n",
    "    createPerformanceOutFiles(Tools,Bases)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Git Labled DS**\n",
    "* Call generateTags method to git the labeled DS as follow: generateTags('Tool Name',reportSource)\n",
    "* reportSource is an integer number 0 or 1.\n",
    "    - 0: Tool is used directly.\n",
    "    - 1: Smartbugs framework is used to run the tool.\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.1 MAIAN-based Labeled DS**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIANDS =pd.DataFrame(generateTags('MAIAN',1))\n",
    "MAIANDS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.2. Mythril-based Labeled DS**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MythrilDS =pd.DataFrame(generateTags('Mythril',0))\n",
    "MythrilDS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.3. Semgrep-based Labeled DS**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SemgrepDS =pd.DataFrame(generateTags('Semgrep',1))\n",
    "SemgrepDS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.4. Slither-based Labeled DS**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SlitherDS =pd.DataFrame(generateTags('Slither',0))\n",
    "SlitherDS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.5. Solhint-based Labeled DS**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SolhintDS =pd.DataFrame(generateTags('Solhint',0))\n",
    "SolhintDS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.6. VeriSmart-based Labeled DS**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VeriSmartDS =pd.DataFrame(generateTags('VeriSmart',0))\n",
    "VeriSmartDS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.Get vote-based labeled data**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1. Fair vote**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledDS =electLabel(['all'],Fair=True)\n",
    "labeledDS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2. UnFair vote**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledDS =electLabel(['all'],Fair=False)\n",
    "labeledDS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Performance Evaluation of Analysis Tools**\n",
    "* **Selected Benchmarks:**\n",
    "    *   **1. SBcurated:** SCs were picked from other collections and manually assessed.\n",
    "    *   **2. SolidiFI:** Injecting 7 types of bugs.\n",
    "    *   **3. Doublade:** \n",
    "    *   **4. JiuZhou:** \n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.0. Base Data: TestSet.csv**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.0.1. MAIAN**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('MAIAN','TestSet.csv',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('MAIAN','TestSet.csv',False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.0.2. Mythril**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('Mythril','TestSet.csv',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('Mythril','TestSet.csv',False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.0.3. Semgrep**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('Semgrep','TestSet.csv',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('Semgrep','TestSet.csv',False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.0.4. Slither**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('Slither','TestSet.csv',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('Slither','TestSet.csv',False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.0.5. Solhint**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('Solhint','TestSet.csv',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('Solhint','TestSet.csv',False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.0.6. VeriSmart**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('VeriSmart','TestSet.csv',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('VeriSmart','TestSet.csv',False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.0.7. Vote**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.0.7.1. AtLeastOne Voting**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('vote_AtLeastOne','TestSet.csv',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('vote_AtLeastOne','TestSet.csv',False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.0.7.2.  Majority Voting**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('vote_Majority','TestSet.csv',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('vote_Majority','TestSet.csv',False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.0.7.3.  Power-based Voting**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('vote_Power-based','TestSet.csv',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('vote_Power-based','TestSet.csv',False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Plot Evaluation Results**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.1. Many Tools on Many Bases**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eval_Results = plot_result(['All'],['SolidiFI','Doublade','JiuZhou','SBcurated'],Fair=True)\n",
    "Eval_Results.to_csv('./MultiTagging/Results/Charts/Performance/ToolsPerformanceOnOneManyBases_Fair.csv',index=False)\n",
    "Eval_Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.2. Many Tools on One Base**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2.1. Fair Evaluation**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance of analysis tools\n",
    "Eval_Results = plot_result(['MAIAN','Mythril','Semgrep','Slither','Solhint','VeriSmart'],['TestSet'],Fair=True)\n",
    "Eval_Results.to_csv('./MultiTagging/Results/Charts/Performance/ToolsPerformanceOnOneBase_Fair.csv',index=False)\n",
    "Eval_Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance of analysis tools and voting methods\n",
    "Eval_Results = plot_result(['All'],['TestSet'],Fair=True)\n",
    "Eval_Results.to_csv('./MultiTagging/Results/Charts/Performance/ToolsAndVotePerformanceOnOneBase_Fair.csv',index=False)\n",
    "Eval_Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2.2. UnFair Evaluation**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance of analysis tools\n",
    "Eval_Results = plot_result(['MAIAN','Mythril','Semgrep','Slither','Solhint','VeriSmart'],['TestSet'],Fair=True)\n",
    "Eval_Results.to_csv('./MultiTagging/Results/Charts/Performance/ToolsPerformanceOnOneBase_UnFair.csv',index=False)\n",
    "Eval_Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance of analysis tools and voting methods\n",
    "Eval_Results = plot_result(['All'],['TestSet'],Fair=True)\n",
    "Eval_Results.to_csv('./MultiTagging/Results/Charts/Performance/ToolsAndVotePerformanceOnOneBase_UnFair.csv',index=False)\n",
    "Eval_Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.3. One Tool on One Base**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eval_Results = plot_result(['Slither'],['TestSet'],Fair=True)\n",
    "Eval_Results.to_csv('./MultiTagging/Results/Charts/Performance/OneToolPerformanceOnOneBase.csv',index=False)\n",
    "Eval_Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Get Tools Overlap Degree**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.1. Overlap based on flagged data**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1.1. Unfair**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapDF = getOverlap(['MAIAN','Mythril','Semgrep','Slither','Solhint','VeriSmart'],False)\n",
    "overlapDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1.2. Fair**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapDF = getOverlap(['MAIAN','Mythril','Semgrep','Slither','Solhint','VeriSmart'],True)\n",
    "overlapDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.2. Overlep perVuln**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.2.1. Unfair**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapDF = getOverlapPerV(['MAIAN','Mythril','Semgrep','Slither','Solhint','VeriSmart'],False)\n",
    "overlapDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.2.2. Fair**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapDF = getOverlapPerV(['MAIAN','Mythril','Semgrep','Slither','Solhint','VeriSmart'],True)\n",
    "overlapDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Tools Efficiency**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UnFair Evaluation\n",
    "get_toolEfficiency(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UnFair Evaluation\n",
    "get_toolEfficiency(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
